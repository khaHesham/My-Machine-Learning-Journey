

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

<meta property="og:title" content="sklearn.ensemble.HistGradientBoostingRegressor" />
  
<meta property="og:type" content="website" />
  
<meta property="og:url" content="https://scikit-learn/stable/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html" />
  
<meta property="og:site_name" content="scikit-learn" />
  
<meta property="og:description" content="Examples using sklearn.ensemble.HistGradientBoostingRegressor: Release Highlights for scikit-learn 1.1 Release Highlights for scikit-learn 1.1 Release Highlights for scikit-learn 1.0 Release Highli..." />
  
<meta property="og:image" content="https://scikit-learn/stable/_images/sphx_glr_plot_release_highlights_1_1_0_thumb.png" />
  
<meta property="og:image:alt" content="Release Highlights for scikit-learn 1.1" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>sklearn.ensemble.HistGradientBoostingRegressor &mdash; scikit-learn 1.1.2 documentation</title>
  
  <link rel="canonical" href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html" />

  
  <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  

  <link rel="stylesheet" href="../../_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/plot_directive.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
<script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
<script src="../../_static/jquery.js"></script> 
</head>
<body>






<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
      <a class="navbar-brand py-0" href="../../index.html">
        <img
          class="sk-brand-img"
          src="../../_static/scikit-learn-logo-small.png"
          alt="logo"/>
      </a>
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../install.html">Install</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../user_guide.html">User Guide</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../classes.html">API</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../auto_examples/index.html">Examples</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" target="_blank" rel="noopener noreferrer" href="https://blog.scikit-learn.org/">Community</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../getting_started.html" >Getting Started</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../tutorial/index.html" >Tutorial</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../whats_new/v1.1.html" >What's new</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../glossary.html" >Glossary</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://scikit-learn.org/dev/developers/index.html" target="_blank" rel="noopener noreferrer">Development</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../faq.html" >FAQ</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../support.html" >Support</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../related_projects.html" >Related packages</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../roadmap.html" >Roadmap</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../about.html" >About us</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://github.com/scikit-learn/scikit-learn" >GitHub</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://scikit-learn.org/dev/versions.html" >Other Versions and Download</a>
        </li>
        <li class="nav-item dropdown nav-more-item-dropdown">
          <a class="sk-nav-link nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">More</a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="sk-nav-dropdown-item dropdown-item" href="../../getting_started.html" >Getting Started</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../tutorial/index.html" >Tutorial</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../whats_new/v1.1.html" >What's new</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../glossary.html" >Glossary</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://scikit-learn.org/dev/developers/index.html" target="_blank" rel="noopener noreferrer">Development</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../faq.html" >FAQ</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../support.html" >Support</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../related_projects.html" >Related packages</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../roadmap.html" >Roadmap</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../about.html" >About us</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://github.com/scikit-learn/scikit-learn" >GitHub</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://scikit-learn.org/dev/versions.html" >Other Versions and Download</a>
          </div>
        </li>
      </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="../../search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Go" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
<div class="d-flex" id="sk-doc-wrapper">
    <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
    <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Toggle Menu</label>
    <div id="sk-sidebar-wrapper" class="border-right">
      <div class="sk-sidebar-toc-wrapper">
        <div class="sk-sidebar-toc-logo">
          <a href="../../index.html">
            <img
              class="sk-brand-img"
              src="../../_static/scikit-learn-logo-small.png"
              alt="logo"/>
          </a>
        </div>
        <div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
            <a href="sklearn.ensemble.VotingRegressor.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="sklearn.ensemble.VotingRegressor">Prev</a><a href="../classes.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="API Reference">Up</a>
            <a href="sklearn.ensemble.HistGradientBoostingClassifier.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="sklearn.ensemble.HistGradientBoostingClassifier">Next</a>
        </div>
        <div class="alert alert-danger p-1 mb-2" role="alert">
          <p class="text-center mb-0">
          <strong>scikit-learn 1.1.2</strong><br/>
          <a href="http://scikit-learn.org/dev/versions.html">Other versions</a>
          </p>
        </div>
        <div class="alert alert-warning p-1 mb-2" role="alert">
          <p class="text-center mb-0">
            Please <a class="font-weight-bold" href="../../about.html#citing-scikit-learn"><string>cite us</string></a> if you use the software.
          </p>
        </div>
            <div class="sk-sidebar-toc">
              <ul>
<li><a class="reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.ensemble</span></code>.HistGradientBoostingRegressor</a><ul>
<li><a class="reference internal" href="#examples-using-sklearn-ensemble-histgradientboostingregressor">Examples using <code class="docutils literal notranslate"><span class="pre">sklearn.ensemble.HistGradientBoostingRegressor</span></code></a></li>
</ul>
</li>
</ul>

            </div>
      </div>
    </div>
    <div id="sk-page-content-wrapper">
      <div class="sk-page-content container-fluid body px-md-3" role="main">
        
  <section id="sklearn-ensemble-histgradientboostingregressor">
<h1><a class="reference internal" href="../classes.html#module-sklearn.ensemble" title="sklearn.ensemble"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.ensemble</span></code></a>.HistGradientBoostingRegressor<a class="headerlink" href="#sklearn-ensemble-histgradientboostingregressor" title="Permalink to this heading">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="sklearn.ensemble.HistGradientBoostingRegressor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sklearn.ensemble.</span></span><span class="sig-name descname"><span class="pre">HistGradientBoostingRegressor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'squared_error'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quantile</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_leaf_nodes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">31</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">l2_regularization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_bins</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">255</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">categorical_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">monotonic_cst</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validation_fraction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_iter_no_change</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/36958fb24/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py#L1099"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sklearn.ensemble.HistGradientBoostingRegressor" title="Permalink to this definition">¶</a></dt>
<dd><p>Histogram-based Gradient Boosting Regression Tree.</p>
<p>This estimator is much faster than
<a class="reference internal" href="sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor" title="sklearn.ensemble.GradientBoostingRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingRegressor</span></code></a>
for big datasets (n_samples &gt;= 10 000).</p>
<p>This estimator has native support for missing values (NaNs). During
training, the tree grower learns at each split point whether samples
with missing values should go to the left or right child, based on the
potential gain. When predicting, samples with missing values are
assigned to the left or right child consequently. If no missing values
were encountered for a given feature during training, then samples with
missing values are mapped to whichever child has the most samples.</p>
<p>This implementation is inspired by
<a class="reference external" href="https://github.com/Microsoft/LightGBM">LightGBM</a>.</p>
<p>Read more in the <a class="reference internal" href="../ensemble.html#histogram-based-gradient-boosting"><span class="std std-ref">User Guide</span></a>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.21.</span></p>
</div>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>loss</strong><span class="classifier">{‘squared_error’, ‘absolute_error’, ‘poisson’, ‘quantile’},             default=’squared_error’</span></dt><dd><p>The loss function to use in the boosting process. Note that the
“squared error” and “poisson” losses actually implement
“half least squares loss” and “half poisson deviance” to simplify the
computation of the gradient. Furthermore, “poisson” loss internally
uses a log-link and requires <code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">&gt;=</span> <span class="pre">0</span></code>.
“quantile” uses the pinball loss.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.23: </span>Added option ‘poisson’.</p>
</div>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 1.1: </span>Added option ‘quantile’.</p>
</div>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.0: </span>The loss ‘least_squares’ was deprecated in v1.0 and will be removed
in version 1.2. Use <code class="docutils literal notranslate"><span class="pre">loss='squared_error'</span></code> which is equivalent.</p>
</div>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.0: </span>The loss ‘least_absolute_deviation’ was deprecated in v1.0 and will
be removed in version 1.2. Use <code class="docutils literal notranslate"><span class="pre">loss='absolute_error'</span></code> which is
equivalent.</p>
</div>
</dd>
<dt><strong>quantile</strong><span class="classifier">float, default=None</span></dt><dd><p>If loss is “quantile”, this parameter specifies which quantile to be estimated
and must be between 0 and 1.</p>
</dd>
<dt><strong>learning_rate</strong><span class="classifier">float, default=0.1</span></dt><dd><p>The learning rate, also known as <em>shrinkage</em>. This is used as a
multiplicative factor for the leaves values. Use <code class="docutils literal notranslate"><span class="pre">1</span></code> for no
shrinkage.</p>
</dd>
<dt><strong>max_iter</strong><span class="classifier">int, default=100</span></dt><dd><p>The maximum number of iterations of the boosting process, i.e. the
maximum number of trees.</p>
</dd>
<dt><strong>max_leaf_nodes</strong><span class="classifier">int or None, default=31</span></dt><dd><p>The maximum number of leaves for each tree. Must be strictly greater
than 1. If None, there is no maximum limit.</p>
</dd>
<dt><strong>max_depth</strong><span class="classifier">int or None, default=None</span></dt><dd><p>The maximum depth of each tree. The depth of a tree is the number of
edges to go from the root to the deepest leaf.
Depth isn’t constrained by default.</p>
</dd>
<dt><strong>min_samples_leaf</strong><span class="classifier">int, default=20</span></dt><dd><p>The minimum number of samples per leaf. For small datasets with less
than a few hundred samples, it is recommended to lower this value
since only very shallow trees would be built.</p>
</dd>
<dt><strong>l2_regularization</strong><span class="classifier">float, default=0</span></dt><dd><p>The L2 regularization parameter. Use <code class="docutils literal notranslate"><span class="pre">0</span></code> for no regularization
(default).</p>
</dd>
<dt><strong>max_bins</strong><span class="classifier">int, default=255</span></dt><dd><p>The maximum number of bins to use for non-missing values. Before
training, each feature of the input array <code class="docutils literal notranslate"><span class="pre">X</span></code> is binned into
integer-valued bins, which allows for a much faster training stage.
Features with a small number of unique values may use less than
<code class="docutils literal notranslate"><span class="pre">max_bins</span></code> bins. In addition to the <code class="docutils literal notranslate"><span class="pre">max_bins</span></code> bins, one more bin
is always reserved for missing values. Must be no larger than 255.</p>
</dd>
<dt><strong>categorical_features</strong><span class="classifier">array-like of {bool, int} of shape (n_features)             or shape (n_categorical_features,), default=None</span></dt><dd><p>Indicates the categorical features.</p>
<ul class="simple">
<li><p>None : no feature will be considered categorical.</p></li>
<li><p>boolean array-like : boolean mask indicating categorical features.</p></li>
<li><p>integer array-like : integer indices indicating categorical
features.</p></li>
</ul>
<p>For each categorical feature, there must be at most <code class="docutils literal notranslate"><span class="pre">max_bins</span></code> unique
categories, and each categorical value must be in [0, max_bins -1].</p>
<p>Read more in the <a class="reference internal" href="../ensemble.html#categorical-support-gbdt"><span class="std std-ref">User Guide</span></a>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.24.</span></p>
</div>
</dd>
<dt><strong>monotonic_cst</strong><span class="classifier">array-like of int of shape (n_features), default=None</span></dt><dd><p>Indicates the monotonic constraint to enforce on each feature. -1, 1
and 0 respectively correspond to a negative constraint, positive
constraint and no constraint. Read more in the <a class="reference internal" href="../ensemble.html#monotonic-cst-gbdt"><span class="std std-ref">User Guide</span></a>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.23.</span></p>
</div>
</dd>
<dt><strong>warm_start</strong><span class="classifier">bool, default=False</span></dt><dd><p>When set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, reuse the solution of the previous call to fit
and add more estimators to the ensemble. For results to be valid, the
estimator should be re-trained on the same data only.
See <a class="reference internal" href="../../glossary.html#term-warm_start"><span class="xref std std-term">the Glossary</span></a>.</p>
</dd>
<dt><strong>early_stopping</strong><span class="classifier">‘auto’ or bool, default=’auto’</span></dt><dd><p>If ‘auto’, early stopping is enabled if the sample size is larger than
10000. If True, early stopping is enabled, otherwise early stopping is
disabled.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.23.</span></p>
</div>
</dd>
<dt><strong>scoring</strong><span class="classifier">str or callable or None, default=’loss’</span></dt><dd><p>Scoring parameter to use for early stopping. It can be a single
string (see <a class="reference internal" href="../model_evaluation.html#scoring-parameter"><span class="std std-ref">The scoring parameter: defining model evaluation rules</span></a>) or a callable (see
<a class="reference internal" href="../model_evaluation.html#scoring"><span class="std std-ref">Defining your scoring strategy from metric functions</span></a>). If None, the estimator’s default scorer is used. If
<code class="docutils literal notranslate"><span class="pre">scoring='loss'</span></code>, early stopping is checked w.r.t the loss value.
Only used if early stopping is performed.</p>
</dd>
<dt><strong>validation_fraction</strong><span class="classifier">int or float or None, default=0.1</span></dt><dd><p>Proportion (or absolute size) of training data to set aside as
validation data for early stopping. If None, early stopping is done on
the training data. Only used if early stopping is performed.</p>
</dd>
<dt><strong>n_iter_no_change</strong><span class="classifier">int, default=10</span></dt><dd><p>Used to determine when to “early stop”. The fitting process is
stopped when none of the last <code class="docutils literal notranslate"><span class="pre">n_iter_no_change</span></code> scores are better
than the <code class="docutils literal notranslate"><span class="pre">n_iter_no_change</span> <span class="pre">-</span> <span class="pre">1</span></code> -th-to-last one, up to some
tolerance. Only used if early stopping is performed.</p>
</dd>
<dt><strong>tol</strong><span class="classifier">float, default=1e-7</span></dt><dd><p>The absolute tolerance to use when comparing scores during early
stopping. The higher the tolerance, the more likely we are to early
stop: higher tolerance means that it will be harder for subsequent
iterations to be considered an improvement upon the reference score.</p>
</dd>
<dt><strong>verbose</strong><span class="classifier">int, default=0</span></dt><dd><p>The verbosity level. If not zero, print some information about the
fitting process.</p>
</dd>
<dt><strong>random_state</strong><span class="classifier">int, RandomState instance or None, default=None</span></dt><dd><p>Pseudo-random number generator to control the subsampling in the
binning process, and the train/validation data split if early stopping
is enabled.
Pass an int for reproducible output across multiple function calls.
See <a class="reference internal" href="../../glossary.html#term-random_state"><span class="xref std std-term">Glossary</span></a>.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Attributes<span class="colon">:</span></dt>
<dd class="field-even"><dl>
<dt><strong>do_early_stopping_</strong><span class="classifier">bool</span></dt><dd><p>Indicates whether early stopping is used during training.</p>
</dd>
<dt><a class="reference internal" href="#sklearn.ensemble.HistGradientBoostingRegressor.n_iter_" title="sklearn.ensemble.HistGradientBoostingRegressor.n_iter_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">n_iter_</span></code></a><span class="classifier">int</span></dt><dd><p>Number of iterations of the boosting process.</p>
</dd>
<dt><strong>n_trees_per_iteration_</strong><span class="classifier">int</span></dt><dd><p>The number of tree that are built at each iteration. For regressors,
this is always 1.</p>
</dd>
<dt><strong>train_score_</strong><span class="classifier">ndarray, shape (n_iter_+1,)</span></dt><dd><p>The scores at each iteration on the training data. The first entry
is the score of the ensemble before the first iteration. Scores are
computed according to the <code class="docutils literal notranslate"><span class="pre">scoring</span></code> parameter. If <code class="docutils literal notranslate"><span class="pre">scoring</span></code> is
not ‘loss’, scores are computed on a subset of at most 10 000
samples. Empty if no early stopping.</p>
</dd>
<dt><strong>validation_score_</strong><span class="classifier">ndarray, shape (n_iter_+1,)</span></dt><dd><p>The scores at each iteration on the held-out validation data. The
first entry is the score of the ensemble before the first iteration.
Scores are computed according to the <code class="docutils literal notranslate"><span class="pre">scoring</span></code> parameter. Empty if
no early stopping or if <code class="docutils literal notranslate"><span class="pre">validation_fraction</span></code> is None.</p>
</dd>
<dt><strong>is_categorical_</strong><span class="classifier">ndarray, shape (n_features, ) or None</span></dt><dd><p>Boolean mask for the categorical features. <code class="docutils literal notranslate"><span class="pre">None</span></code> if there are no
categorical features.</p>
</dd>
<dt><strong>n_features_in_</strong><span class="classifier">int</span></dt><dd><p>Number of features seen during <a class="reference internal" href="../../glossary.html#term-fit"><span class="xref std std-term">fit</span></a>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.24.</span></p>
</div>
</dd>
<dt><strong>feature_names_in_</strong><span class="classifier">ndarray of shape (<code class="docutils literal notranslate"><span class="pre">n_features_in_</span></code>,)</span></dt><dd><p>Names of features seen during <a class="reference internal" href="../../glossary.html#term-fit"><span class="xref std std-term">fit</span></a>. Defined only when <code class="docutils literal notranslate"><span class="pre">X</span></code>
has feature names that are all strings.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.0.</span></p>
</div>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor" title="sklearn.ensemble.GradientBoostingRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GradientBoostingRegressor</span></code></a></dt><dd><p>Exact gradient boosting method that does not scale as good on datasets with a large number of samples.</p>
</dd>
<dt><a class="reference internal" href="sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor" title="sklearn.tree.DecisionTreeRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sklearn.tree.DecisionTreeRegressor</span></code></a></dt><dd><p>A decision tree regressor.</p>
</dd>
<dt><a class="reference internal" href="sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RandomForestRegressor</span></code></a></dt><dd><p>A meta-estimator that fits a number of decision tree regressors on various sub-samples of the dataset and uses averaging to improve the statistical performance and control over-fitting.</p>
</dd>
<dt><a class="reference internal" href="sklearn.ensemble.AdaBoostRegressor.html#sklearn.ensemble.AdaBoostRegressor" title="sklearn.ensemble.AdaBoostRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AdaBoostRegressor</span></code></a></dt><dd><p>A meta-estimator that begins by fitting a regressor on the original dataset and then fits additional copies of the regressor on the same dataset but where the weights of instances are adjusted according to the error of the current prediction. As such, subsequent regressors focus more on difficult cases.</p>
</dd>
</dl>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">HistGradientBoostingRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">est</span> <span class="o">=</span> <span class="n">HistGradientBoostingRegressor</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">est</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">0.92...</span>
</pre></div>
</div>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.ensemble.HistGradientBoostingRegressor.fit" title="sklearn.ensemble.HistGradientBoostingRegressor.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(X, y[, sample_weight])</p></td>
<td><p>Fit the gradient boosting model.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.ensemble.HistGradientBoostingRegressor.get_params" title="sklearn.ensemble.HistGradientBoostingRegressor.get_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code></a>([deep])</p></td>
<td><p>Get parameters for this estimator.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.ensemble.HistGradientBoostingRegressor.predict" title="sklearn.ensemble.HistGradientBoostingRegressor.predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code></a>(X)</p></td>
<td><p>Predict values for X.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.ensemble.HistGradientBoostingRegressor.score" title="sklearn.ensemble.HistGradientBoostingRegressor.score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">score</span></code></a>(X, y[, sample_weight])</p></td>
<td><p>Return the coefficient of determination of the prediction.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.ensemble.HistGradientBoostingRegressor.set_params" title="sklearn.ensemble.HistGradientBoostingRegressor.set_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code></a>(**params)</p></td>
<td><p>Set the parameters of this estimator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.ensemble.HistGradientBoostingRegressor.staged_predict" title="sklearn.ensemble.HistGradientBoostingRegressor.staged_predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">staged_predict</span></code></a>(X)</p></td>
<td><p>Predict regression target for each iteration.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.ensemble.HistGradientBoostingRegressor.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/36958fb24/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py#L260"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sklearn.ensemble.HistGradientBoostingRegressor.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the gradient boosting model.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>X</strong><span class="classifier">array-like of shape (n_samples, n_features)</span></dt><dd><p>The input samples.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array-like of shape (n_samples,)</span></dt><dd><p>Target values.</p>
</dd>
<dt><strong>sample_weight</strong><span class="classifier">array-like of shape (n_samples,) default=None</span></dt><dd><p>Weights of training data.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.23.</span></p>
</div>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">object</span></dt><dd><p>Fitted estimator.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.ensemble.HistGradientBoostingRegressor.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/36958fb24/sklearn/base.py#L194"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sklearn.ensemble.HistGradientBoostingRegressor.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>deep</strong><span class="classifier">bool, default=True</span></dt><dd><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>params</strong><span class="classifier">dict</span></dt><dd><p>Parameter names mapped to their values.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="sklearn.ensemble.HistGradientBoostingRegressor.n_iter_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_iter_</span></span><a class="headerlink" href="#sklearn.ensemble.HistGradientBoostingRegressor.n_iter_" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of iterations of the boosting process.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.ensemble.HistGradientBoostingRegressor.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/36958fb24/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py#L1358"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sklearn.ensemble.HistGradientBoostingRegressor.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict values for X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like, shape (n_samples, n_features)</span></dt><dd><p>The input samples.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>y</strong><span class="classifier">ndarray, shape (n_samples,)</span></dt><dd><p>The predicted values.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.ensemble.HistGradientBoostingRegressor.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/36958fb24/sklearn/base.py#L677"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sklearn.ensemble.HistGradientBoostingRegressor.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the coefficient of determination of the prediction.</p>
<p>The coefficient of determination <span class="math notranslate nohighlight">\(R^2\)</span> is defined as
<span class="math notranslate nohighlight">\((1 - \frac{u}{v})\)</span>, where <span class="math notranslate nohighlight">\(u\)</span> is the residual
sum of squares <code class="docutils literal notranslate"><span class="pre">((y_true</span> <span class="pre">-</span> <span class="pre">y_pred)**</span> <span class="pre">2).sum()</span></code> and <span class="math notranslate nohighlight">\(v\)</span>
is the total sum of squares <code class="docutils literal notranslate"><span class="pre">((y_true</span> <span class="pre">-</span> <span class="pre">y_true.mean())</span> <span class="pre">**</span> <span class="pre">2).sum()</span></code>.
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always predicts
the expected value of <code class="docutils literal notranslate"><span class="pre">y</span></code>, disregarding the input features, would get
a <span class="math notranslate nohighlight">\(R^2\)</span> score of 0.0.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like of shape (n_samples, n_features)</span></dt><dd><p>Test samples. For some estimators this may be a precomputed
kernel matrix or a list of generic objects instead with shape
<code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_samples_fitted)</span></code>, where <code class="docutils literal notranslate"><span class="pre">n_samples_fitted</span></code>
is the number of samples used in the fitting for the estimator.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array-like of shape (n_samples,) or (n_samples, n_outputs)</span></dt><dd><p>True values for <code class="docutils literal notranslate"><span class="pre">X</span></code>.</p>
</dd>
<dt><strong>sample_weight</strong><span class="classifier">array-like of shape (n_samples,), default=None</span></dt><dd><p>Sample weights.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>score</strong><span class="classifier">float</span></dt><dd><p><span class="math notranslate nohighlight">\(R^2\)</span> of <code class="docutils literal notranslate"><span class="pre">self.predict(X)</span></code> wrt. <code class="docutils literal notranslate"><span class="pre">y</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The <span class="math notranslate nohighlight">\(R^2\)</span> score used when calling <code class="docutils literal notranslate"><span class="pre">score</span></code> on a regressor uses
<code class="docutils literal notranslate"><span class="pre">multioutput='uniform_average'</span></code> from version 0.23 to keep consistent
with default value of <a class="reference internal" href="sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="sklearn.metrics.r2_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">r2_score</span></code></a>.
This influences the <code class="docutils literal notranslate"><span class="pre">score</span></code> method of all the multioutput
regressors (except for
<a class="reference internal" href="sklearn.multioutput.MultiOutputRegressor.html#sklearn.multioutput.MultiOutputRegressor" title="sklearn.multioutput.MultiOutputRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiOutputRegressor</span></code></a>).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.ensemble.HistGradientBoostingRegressor.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/36958fb24/sklearn/base.py#L218"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sklearn.ensemble.HistGradientBoostingRegressor.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as <a class="reference internal" href="sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a>). The latter have
parameters of the form <code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s
possible to update each component of a nested object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>**params</strong><span class="classifier">dict</span></dt><dd><p>Estimator parameters.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">estimator instance</span></dt><dd><p>Estimator instance.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.ensemble.HistGradientBoostingRegressor.staged_predict">
<span class="sig-name descname"><span class="pre">staged_predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/36958fb24/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py#L1376"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sklearn.ensemble.HistGradientBoostingRegressor.staged_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict regression target for each iteration.</p>
<p>This method allows monitoring (i.e. determine error on testing set)
after each stage.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.24.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like of shape (n_samples, n_features)</span></dt><dd><p>The input samples.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Yields<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>y</strong><span class="classifier">generator of ndarray of shape (n_samples,)</span></dt><dd><p>The predicted values of the input samples, for each iteration.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<section id="examples-using-sklearn-ensemble-histgradientboostingregressor">
<h2>Examples using <code class="docutils literal notranslate"><span class="pre">sklearn.ensemble.HistGradientBoostingRegressor</span></code><a class="headerlink" href="#examples-using-sklearn-ensemble-histgradientboostingregressor" title="Permalink to this heading">¶</a></h2>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="We are pleased to announce the release of scikit-learn 1.1! Many bug fixes and improvements wer..."><img alt="Release Highlights for scikit-learn 1.1" src="../../_images/sphx_glr_plot_release_highlights_1_1_0_thumb.png" />
<p><a class="reference internal" href="../../auto_examples/release_highlights/plot_release_highlights_1_1_0.html#sphx-glr-auto-examples-release-highlights-plot-release-highlights-1-1-0-py"><span class="std std-ref">Release Highlights for scikit-learn 1.1</span></a></p>
  <div class="sphx-glr-thumbnail-title">Release Highlights for scikit-learn 1.1</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="We are very pleased to announce the release of scikit-learn 1.0! The library has been stable fo..."><img alt="Release Highlights for scikit-learn 1.0" src="../../_images/sphx_glr_plot_release_highlights_1_0_0_thumb.png" />
<p><a class="reference internal" href="../../auto_examples/release_highlights/plot_release_highlights_1_0_0.html#sphx-glr-auto-examples-release-highlights-plot-release-highlights-1-0-0-py"><span class="std std-ref">Release Highlights for scikit-learn 1.0</span></a></p>
  <div class="sphx-glr-thumbnail-title">Release Highlights for scikit-learn 1.0</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="We are pleased to announce the release of scikit-learn 0.24! Many bug fixes and improvements we..."><img alt="Release Highlights for scikit-learn 0.24" src="../../_images/sphx_glr_plot_release_highlights_0_24_0_thumb.png" />
<p><a class="reference internal" href="../../auto_examples/release_highlights/plot_release_highlights_0_24_0.html#sphx-glr-auto-examples-release-highlights-plot-release-highlights-0-24-0-py"><span class="std std-ref">Release Highlights for scikit-learn 0.24</span></a></p>
  <div class="sphx-glr-thumbnail-title">Release Highlights for scikit-learn 0.24</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="We are pleased to announce the release of scikit-learn 0.23! Many bug fixes and improvements we..."><img alt="Release Highlights for scikit-learn 0.23" src="../../_images/sphx_glr_plot_release_highlights_0_23_0_thumb.png" />
<p><a class="reference internal" href="../../auto_examples/release_highlights/plot_release_highlights_0_23_0.html#sphx-glr-auto-examples-release-highlights-plot-release-highlights-0-23-0-py"><span class="std std-ref">Release Highlights for scikit-learn 0.23</span></a></p>
  <div class="sphx-glr-thumbnail-title">Release Highlights for scikit-learn 0.23</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we will compare the training times and prediction performances of HistGradient..."><img alt="Categorical Feature Support in Gradient Boosting" src="../../_images/sphx_glr_plot_gradient_boosting_categorical_thumb.png" />
<p><a class="reference internal" href="../../auto_examples/ensemble/plot_gradient_boosting_categorical.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-categorical-py"><span class="std std-ref">Categorical Feature Support in Gradient Boosting</span></a></p>
  <div class="sphx-glr-thumbnail-title">Categorical Feature Support in Gradient Boosting</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Stacking refers to a method to blend estimators. In this strategy, some estimators are individu..."><img alt="Combine predictors using stacking" src="../../_images/sphx_glr_plot_stack_predictors_thumb.png" />
<p><a class="reference internal" href="../../auto_examples/ensemble/plot_stack_predictors.html#sphx-glr-auto-examples-ensemble-plot-stack-predictors-py"><span class="std std-ref">Combine predictors using stacking</span></a></p>
  <div class="sphx-glr-thumbnail-title">Combine predictors using stacking</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates Gradient Boosting to produce a predictive model from an ensemble of w..."><img alt="Gradient Boosting regression" src="../../_images/sphx_glr_plot_gradient_boosting_regression_thumb.png" />
<p><a class="reference internal" href="../../auto_examples/ensemble/plot_gradient_boosting_regression.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-regression-py"><span class="std std-ref">Gradient Boosting regression</span></a></p>
  <div class="sphx-glr-thumbnail-title">Gradient Boosting regression</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example illustrates the effect of monotonic constraints on a gradient boosting estimator."><img alt="Monotonic Constraints" src="../../_images/sphx_glr_plot_monotonic_constraints_thumb.png" />
<p><a class="reference internal" href="../../auto_examples/ensemble/plot_monotonic_constraints.html#sphx-glr-auto-examples-ensemble-plot-monotonic-constraints-py"><span class="std std-ref">Monotonic Constraints</span></a></p>
  <div class="sphx-glr-thumbnail-title">Monotonic Constraints</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how quantile regression can be used to create prediction intervals."><img alt="Prediction Intervals for Gradient Boosting Regression" src="../../_images/sphx_glr_plot_gradient_boosting_quantile_thumb.png" />
<p><a class="reference internal" href="../../auto_examples/ensemble/plot_gradient_boosting_quantile.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-quantile-py"><span class="std std-ref">Prediction Intervals for Gradient Boosting Regression</span></a></p>
  <div class="sphx-glr-thumbnail-title">Prediction Intervals for Gradient Boosting Regression</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Demonstrate how model complexity influences both prediction accuracy and computational performa..."><img alt="Model Complexity Influence" src="../../_images/sphx_glr_plot_model_complexity_influence_thumb.png" />
<p><a class="reference internal" href="../../auto_examples/applications/plot_model_complexity_influence.html#sphx-glr-auto-examples-applications-plot-model-complexity-influence-py"><span class="std std-ref">Model Complexity Influence</span></a></p>
  <div class="sphx-glr-thumbnail-title">Model Complexity Influence</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This notebook introduces different strategies to leverage time-related features for a bike shar..."><img alt="Time-related feature engineering" src="../../_images/sphx_glr_plot_cyclical_feature_engineering_thumb.png" />
<p><a class="reference internal" href="../../auto_examples/applications/plot_cyclical_feature_engineering.html#sphx-glr-auto-examples-applications-plot-cyclical-feature-engineering-py"><span class="std std-ref">Time-related feature engineering</span></a></p>
  <div class="sphx-glr-thumbnail-title">Time-related feature engineering</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example illustrates the use of log-linear Poisson regression on the `French Motor Third-Pa..."><img alt="Poisson regression and non-normal loss" src="../../_images/sphx_glr_plot_poisson_regression_non_normal_loss_thumb.png" />
<p><a class="reference internal" href="../../auto_examples/linear_model/plot_poisson_regression_non_normal_loss.html#sphx-glr-auto-examples-linear-model-plot-poisson-regression-non-normal-loss-py"><span class="std std-ref">Poisson regression and non-normal loss</span></a></p>
  <div class="sphx-glr-thumbnail-title">Poisson regression and non-normal loss</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Partial dependence plots show the dependence between the target function [2]_ and a set of feat..."><img alt="Partial Dependence and Individual Conditional Expectation Plots" src="../../_images/sphx_glr_plot_partial_dependence_thumb.png" />
<p><a class="reference internal" href="../../auto_examples/inspection/plot_partial_dependence.html#sphx-glr-auto-examples-inspection-plot-partial-dependence-py"><span class="std std-ref">Partial Dependence and Individual Conditional Expectation Plots</span></a></p>
  <div class="sphx-glr-thumbnail-title">Partial Dependence and Individual Conditional Expectation Plots</div>
</div></div><div class="clearer"></div></section>
</section>


      </div>
    <div class="container">
      <footer class="sk-content-footer">
            &copy; 2007 - 2022, scikit-learn developers (BSD License).
          <a href="../../_sources/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.rst.txt" rel="nofollow">Show this page source</a>
      </footer>
    </div>
  </div>
</div>
<script src="../../_static/js/vendor/bootstrap.min.js"></script>

<script>
    window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
    ga('create', 'UA-22606712-2', 'auto');
    ga('set', 'anonymizeIp', true);
    ga('send', 'pageview');
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');
    var hide_text = 'Hide prompts and outputs';
    var show_text = 'Show prompts and outputs';

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        if (jthis.find('.gp').length > 0) {
            var button = $('<span class="copybutton">&gt;&gt;&gt;</span>');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
            jthis.prepend(button);
        }
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

    // define the behavior of the button when it's clicked
    $('.copybutton').click(function(e){
        e.preventDefault();
        var button = $(this);
        if (button.data('hidden') === 'false') {
            // hide the code output
            button.parent().find('.go, .gp, .gt').hide();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'hidden');
            button.css('text-decoration', 'line-through');
            button.attr('title', show_text);
            button.data('hidden', 'true');
        } else {
            // show the code output
            button.parent().find('.go, .gp, .gt').show();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'visible');
            button.css('text-decoration', 'none');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
        }
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">¶</a>');
	});
  /*** Hide navbar when scrolling down ***/
  // Returns true when headerlink target matches hash in url
  (function() {
    hashTargetOnTop = function() {
        var hash = window.location.hash;
        if ( hash.length < 2 ) { return false; }

        var target = document.getElementById( hash.slice(1) );
        if ( target === null ) { return false; }

        var top = target.getBoundingClientRect().top;
        return (top < 2) && (top > -2);
    };

    // Hide navbar on load if hash target is on top
    var navBar = document.getElementById("navbar");
    var navBarToggler = document.getElementById("sk-navbar-toggler");
    var navBarHeightHidden = "-" + navBar.getBoundingClientRect().height + "px";
    var $window = $(window);

    hideNavBar = function() {
        navBar.style.top = navBarHeightHidden;
    };

    showNavBar = function() {
        navBar.style.top = "0";
    }

    if (hashTargetOnTop()) {
        hideNavBar()
    }

    var prevScrollpos = window.pageYOffset;
    hideOnScroll = function(lastScrollTop) {
        if (($window.width() < 768) && (navBarToggler.getAttribute("aria-expanded") === 'true')) {
            return;
        }
        if (lastScrollTop > 2 && (prevScrollpos <= lastScrollTop) || hashTargetOnTop()){
            hideNavBar()
        } else {
            showNavBar()
        }
        prevScrollpos = lastScrollTop;
    };

    /*** high performance scroll event listener***/
    var raf = window.requestAnimationFrame ||
        window.webkitRequestAnimationFrame ||
        window.mozRequestAnimationFrame ||
        window.msRequestAnimationFrame ||
        window.oRequestAnimationFrame;
    var lastScrollTop = $window.scrollTop();

    if (raf) {
        loop();
    }

    function loop() {
        var scrollTop = $window.scrollTop();
        if (lastScrollTop === scrollTop) {
            raf(loop);
            return;
        } else {
            lastScrollTop = scrollTop;
            hideOnScroll(lastScrollTop);
            raf(loop);
        }
    }
  })();
});

</script>
    
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    
</body>
</html>