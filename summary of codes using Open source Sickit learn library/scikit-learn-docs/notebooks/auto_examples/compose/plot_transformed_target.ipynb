{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Effect of transforming the targets in regression model\n\nIn this example, we give an overview of\n:class:`~sklearn.compose.TransformedTargetRegressor`. We use two examples\nto illustrate the benefit of transforming the targets before learning a linear\nregression model. The first example uses synthetic data while the second\nexample is based on the Ames housing data set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Guillaume Lemaitre <guillaume.lemaitre@inria.fr>\n# License: BSD 3 clause\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.compose import TransformedTargetRegressor\nfrom sklearn.metrics import median_absolute_error, r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Synthetic example\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A synthetic random regression dataset is generated. The targets ``y`` are\nmodified by:\n\n  1. translating all targets such that all entries are\n     non-negative (by adding the absolute value of the lowest ``y``) and\n  2. applying an exponential function to obtain non-linear\n     targets which cannot be fitted using a simple linear model.\n\nTherefore, a logarithmic (`np.log1p`) and an exponential function\n(`np.expm1`) will be used to transform the targets before training a linear\nregression model and using it for prediction.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X, y = make_regression(n_samples=10000, noise=100, random_state=0)\ny = np.expm1((y + abs(y.min())) / 200)\ny_trans = np.log1p(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below we plot the probability density functions of the target\nbefore and after applying the logarithmic functions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "f, (ax0, ax1) = plt.subplots(1, 2)\n\nax0.hist(y, bins=100, density=True)\nax0.set_xlim([0, 2000])\nax0.set_ylabel(\"Probability\")\nax0.set_xlabel(\"Target\")\nax0.set_title(\"Target distribution\")\n\nax1.hist(y_trans, bins=100, density=True)\nax1.set_ylabel(\"Probability\")\nax1.set_xlabel(\"Target\")\nax1.set_title(\"Transformed target distribution\")\n\nf.suptitle(\"Synthetic data\", y=0.06, x=0.53)\nf.tight_layout(rect=[0.05, 0.05, 0.95, 0.95])\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At first, a linear model will be applied on the original targets. Due to the\nnon-linearity, the model trained will not be precise during\nprediction. Subsequently, a logarithmic function is used to linearize the\ntargets, allowing better prediction even with a similar linear model as\nreported by the median absolute error (MAE).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n# Use linear model\nregr = RidgeCV()\nregr.fit(X_train, y_train)\ny_pred = regr.predict(X_test)\n# Plot results\nax0.scatter(y_test, y_pred)\nax0.plot([0, 2000], [0, 2000], \"--k\")\nax0.set_ylabel(\"Target predicted\")\nax0.set_xlabel(\"True Target\")\nax0.set_title(\"Ridge regression \\n without target transformation\")\nax0.text(\n    100,\n    1750,\n    r\"$R^2$=%.2f, MAE=%.2f\"\n    % (r2_score(y_test, y_pred), median_absolute_error(y_test, y_pred)),\n)\nax0.set_xlim([0, 2000])\nax0.set_ylim([0, 2000])\n# Transform targets and use same linear model\nregr_trans = TransformedTargetRegressor(\n    regressor=RidgeCV(), func=np.log1p, inverse_func=np.expm1\n)\nregr_trans.fit(X_train, y_train)\ny_pred = regr_trans.predict(X_test)\n\nax1.scatter(y_test, y_pred)\nax1.plot([0, 2000], [0, 2000], \"--k\")\nax1.set_ylabel(\"Target predicted\")\nax1.set_xlabel(\"True Target\")\nax1.set_title(\"Ridge regression \\n with target transformation\")\nax1.text(\n    100,\n    1750,\n    r\"$R^2$=%.2f, MAE=%.2f\"\n    % (r2_score(y_test, y_pred), median_absolute_error(y_test, y_pred)),\n)\nax1.set_xlim([0, 2000])\nax1.set_ylim([0, 2000])\n\nf.suptitle(\"Synthetic data\", y=0.035)\nf.tight_layout(rect=[0.05, 0.05, 0.95, 0.95])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Real-world data set\n\n In a similar manner, the Ames housing data set is used to show the impact\n of transforming the targets before learning a model. In this example, the\n target to be predicted is the selling price of each house.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\nfrom sklearn.preprocessing import QuantileTransformer, quantile_transform\n\names = fetch_openml(name=\"house_prices\", as_frame=True)\n# Keep only numeric columns\nX = ames.data.select_dtypes(np.number)\n# Remove columns with NaN or Inf values\nX = X.drop(columns=[\"LotFrontage\", \"GarageYrBlt\", \"MasVnrArea\"])\ny = ames.target\ny_trans = quantile_transform(\n    y.to_frame(), n_quantiles=900, output_distribution=\"normal\", copy=True\n).squeeze()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A :class:`~sklearn.preprocessing.QuantileTransformer` is used to normalize\nthe target distribution before applying a\n:class:`~sklearn.linear_model.RidgeCV` model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "f, (ax0, ax1) = plt.subplots(1, 2)\n\nax0.hist(y, bins=100, density=True)\nax0.set_ylabel(\"Probability\")\nax0.set_xlabel(\"Target\")\nax0.text(s=\"Target distribution\", x=1.2e5, y=9.8e-6, fontsize=12)\nax0.ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n\nax1.hist(y_trans, bins=100, density=True)\nax1.set_ylabel(\"Probability\")\nax1.set_xlabel(\"Target\")\nax1.text(s=\"Transformed target distribution\", x=-6.8, y=0.479, fontsize=12)\n\nf.suptitle(\"Ames housing data: selling price\", y=0.04)\nf.tight_layout(rect=[0.05, 0.05, 0.95, 0.95])\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The effect of the transformer is weaker than on the synthetic data. However,\nthe transformation results in an increase in $R^2$ and large decrease\nof the MAE. The residual plot (predicted target - true target vs predicted\ntarget) without target transformation takes on a curved, 'reverse smile'\nshape due to residual values that vary depending on the value of predicted\ntarget. With target transformation, the shape is more linear indicating\nbetter model fit.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "f, (ax0, ax1) = plt.subplots(2, 2, sharey=\"row\", figsize=(6.5, 8))\n\nregr = RidgeCV()\nregr.fit(X_train, y_train)\ny_pred = regr.predict(X_test)\n\nax0[0].scatter(y_pred, y_test, s=8)\nax0[0].plot([0, 7e5], [0, 7e5], \"--k\")\nax0[0].set_ylabel(\"True target\")\nax0[0].set_xlabel(\"Predicted target\")\nax0[0].text(\n    s=\"Ridge regression \\n without target transformation\",\n    x=-5e4,\n    y=8e5,\n    fontsize=12,\n    multialignment=\"center\",\n)\nax0[0].text(\n    3e4,\n    64e4,\n    r\"$R^2$=%.2f, MAE=%.2f\"\n    % (r2_score(y_test, y_pred), median_absolute_error(y_test, y_pred)),\n)\nax0[0].set_xlim([0, 7e5])\nax0[0].set_ylim([0, 7e5])\nax0[0].ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n\nax1[0].scatter(y_pred, (y_pred - y_test), s=8)\nax1[0].set_ylabel(\"Residual\")\nax1[0].set_xlabel(\"Predicted target\")\nax1[0].ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n\nregr_trans = TransformedTargetRegressor(\n    regressor=RidgeCV(),\n    transformer=QuantileTransformer(n_quantiles=900, output_distribution=\"normal\"),\n)\nregr_trans.fit(X_train, y_train)\ny_pred = regr_trans.predict(X_test)\n\nax0[1].scatter(y_pred, y_test, s=8)\nax0[1].plot([0, 7e5], [0, 7e5], \"--k\")\nax0[1].set_ylabel(\"True target\")\nax0[1].set_xlabel(\"Predicted target\")\nax0[1].text(\n    s=\"Ridge regression \\n with target transformation\",\n    x=-5e4,\n    y=8e5,\n    fontsize=12,\n    multialignment=\"center\",\n)\nax0[1].text(\n    3e4,\n    64e4,\n    r\"$R^2$=%.2f, MAE=%.2f\"\n    % (r2_score(y_test, y_pred), median_absolute_error(y_test, y_pred)),\n)\nax0[1].set_xlim([0, 7e5])\nax0[1].set_ylim([0, 7e5])\nax0[1].ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n\nax1[1].scatter(y_pred, (y_pred - y_test), s=8)\nax1[1].set_ylabel(\"Residual\")\nax1[1].set_xlabel(\"Predicted target\")\nax1[1].ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n\nf.suptitle(\"Ames housing data: selling price\", y=0.035)\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}